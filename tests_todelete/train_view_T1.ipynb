{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4bf035",
   "metadata": {},
   "source": [
    "### This is the first test to analyze the data in a train view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048f464",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "\n",
    "inputs:\n",
    "\n",
    "- `train origin and destination`\n",
    "- `date`\n",
    "\n",
    "\n",
    "outputs:\n",
    "\n",
    "- `overall train journey`: what did the train encounter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aed353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully for station_view analysis\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for station_view function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "\n",
    "print(\" Libraries imported successfully for station_view analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc105db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10450237 rows from 2599 files. Skipped 0 files.\n"
     ]
    }
   ],
   "source": [
    "# Load all .parquet files from processed_data into a pandas DataFrame, trying both pyarrow and fastparquet engines\n",
    "\n",
    "data_dir = '../processed_data' if not os.path.isdir('processed_data') else 'processed_data'\n",
    "all_parquet_files = glob.glob(os.path.join(data_dir, '*', '*.parquet'))\n",
    "\n",
    "list_df = []\n",
    "skipped_files = []\n",
    "for file in all_parquet_files:\n",
    "    try:\n",
    "        df = pd.read_parquet(file)\n",
    "    except Exception as e1:\n",
    "        try:\n",
    "            df = pd.read_parquet(file, engine='fastparquet')\n",
    "        except Exception as e2:\n",
    "            skipped_files.append(file)\n",
    "            continue\n",
    "    stanox = os.path.basename(os.path.dirname(file))\n",
    "    day = os.path.splitext(os.path.basename(file))[0]\n",
    "    df['STANOX'] = stanox\n",
    "    df['DAY'] = day\n",
    "    list_df.append(df)\n",
    "\n",
    "if list_df:\n",
    "    all_data = pd.concat(list_df, ignore_index=True)\n",
    "    print(f\"Loaded {len(all_data)} rows from {len(list_df)} files. Skipped {len(skipped_files)} files.\")\n",
    "else:\n",
    "    all_data = pd.DataFrame()\n",
    "    print(\"No data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746f47a",
   "metadata": {},
   "source": [
    "just for quick access during the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d94013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRAIN_SERVICE_CODE',\n",
       " 'PLANNED_ORIGIN_LOCATION_CODE',\n",
       " 'PLANNED_ORIGIN_GBTT_DATETIME',\n",
       " 'PLANNED_DEST_LOCATION_CODE',\n",
       " 'PLANNED_DEST_GBTT_DATETIME',\n",
       " 'PLANNED_CALLS',\n",
       " 'ACTUAL_CALLS',\n",
       " 'PFPI_MINUTES',\n",
       " 'INCIDENT_REASON',\n",
       " 'INCIDENT_NUMBER',\n",
       " 'EVENT_TYPE',\n",
       " 'SECTION_CODE',\n",
       " 'DELAY_DAY',\n",
       " 'EVENT_DATETIME',\n",
       " 'INCIDENT_START_DATETIME',\n",
       " 'ENGLISH_DAY_TYPE',\n",
       " 'STATION_ROLE',\n",
       " 'DFT_CATEGORY',\n",
       " 'PLATFORM_COUNT',\n",
       " 'DATASET_TYPE',\n",
       " 'WEEKDAY',\n",
       " 'STANOX',\n",
       " 'DAY']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns.tolist() # Display the columns of the combined DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0101c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_view(all_data, origin_code, destination_code, input_date_str):\n",
    "    \"\"\"\n",
    "    View all train journeys between an OD pair and check for incidents on a specific date.\n",
    "    Corrects PLANNED_CALLS using ACTUAL_CALLS - PFPI_MINUTES.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data : pd.DataFrame\n",
    "        Must contain:\n",
    "        ['TRAIN_SERVICE_CODE', 'PLANNED_ORIGIN_LOCATION_CODE', 'PLANNED_ORIGIN_GBTT_DATETIME',\n",
    "         'PLANNED_DEST_LOCATION_CODE', 'PLANNED_DEST_GBTT_DATETIME', 'PLANNED_CALLS', 'ACTUAL_CALLS',\n",
    "         'PFPI_MINUTES', 'INCIDENT_REASON', 'INCIDENT_NUMBER', 'EVENT_TYPE', 'SECTION_CODE', 'DELAY_DAY',\n",
    "         'EVENT_DATETIME', 'INCIDENT_START_DATETIME', 'ENGLISH_DAY_TYPE', 'STATION_ROLE', 'DFT_CATEGORY',\n",
    "         'PLATFORM_COUNT', 'DATASET_TYPE', 'WEEKDAY', 'STANOX', 'DAY']\n",
    "    origin_code : str or int\n",
    "        Origin location code.\n",
    "    destination_code : str or int\n",
    "        Destination location code.\n",
    "    input_date_str : str\n",
    "        Date in the format 'DD-MMM-YYYY' (e.g., '13-JUN-2024').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or str\n",
    "        DataFrame of matching incidents (with corrected PLANNED_CALLS) or a message.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Ensure OD_PAIR exists ---\n",
    "    if 'OD_PAIR' not in all_data.columns:\n",
    "        all_data['OD_PAIR'] = (\n",
    "            all_data['PLANNED_ORIGIN_LOCATION_CODE'].astype(str)\n",
    "            + '_'\n",
    "            + all_data['PLANNED_DEST_LOCATION_CODE'].astype(str)\n",
    "        )\n",
    "\n",
    "    # --- Define OD pair key and convert dates ---\n",
    "    od_pair = f\"{origin_code}_{destination_code}\"\n",
    "    input_date = pd.to_datetime(input_date_str, format='%d-%b-%Y', errors='coerce')\n",
    "    all_data['INCIDENT_START_DATETIME'] = pd.to_datetime(\n",
    "        all_data['INCIDENT_START_DATETIME'], errors='coerce'\n",
    "    )\n",
    "\n",
    "    # --- Check if OD pair exists ---\n",
    "    if od_pair not in all_data['OD_PAIR'].unique():\n",
    "        message = f\"OD pair {od_pair} not found in dataset.\"\n",
    "        print(message)\n",
    "        return message\n",
    "\n",
    "    # --- Subset for this OD pair ---\n",
    "    trains_between = all_data[all_data['OD_PAIR'] == od_pair].copy()\n",
    "\n",
    "    # --- Correct PLANNED_CALLS using ACTUAL_CALLS - PFPI_MINUTES ---\n",
    "    trains_between['ACTUAL_CALLS_dt'] = pd.to_datetime(\n",
    "        trains_between['ACTUAL_CALLS'], format='%H%M', errors='coerce'\n",
    "    )\n",
    "    trains_between['PFPI_MINUTES_num'] = pd.to_numeric(\n",
    "        trains_between['PFPI_MINUTES'], errors='coerce'\n",
    "    )\n",
    "\n",
    "    trains_between['CORRECTED_PLANNED_CALLS_dt'] = (\n",
    "        trains_between['ACTUAL_CALLS_dt']\n",
    "        - pd.to_timedelta(trains_between['PFPI_MINUTES_num'].fillna(0), unit='m')\n",
    "    )\n",
    "    trains_between['PLANNED_CALLS'] = trains_between[\n",
    "        'CORRECTED_PLANNED_CALLS_dt'\n",
    "    ].dt.strftime('%H%M').fillna(trains_between['PLANNED_CALLS'])\n",
    "\n",
    "    print(f\" Train journeys between {origin_code} and {destination_code}: {len(trains_between)} records found.\")\n",
    "    print(f\"Unique train service codes: {trains_between['TRAIN_SERVICE_CODE'].dropna().unique().tolist()}\")\n",
    "\n",
    "\n",
    "    # --- Filter incidents by date ---\n",
    "    incidents_on_date = trains_between[\n",
    "        trains_between['INCIDENT_START_DATETIME'].dt.date == input_date.date()\n",
    "    ].copy()\n",
    "\n",
    "    if incidents_on_date.empty:\n",
    "        message = f\" No incidents found for OD pair {od_pair} on {input_date_str}.\"\n",
    "        print(message)\n",
    "        return message\n",
    "    else:\n",
    "        message = f\" {len(incidents_on_date)} incident(s) found for OD pair {od_pair} on {input_date_str}:\"\n",
    "        print(message)\n",
    "\n",
    "        # --- Columns to show ---\n",
    "        cols_to_show = [\n",
    "            'TRAIN_SERVICE_CODE', 'PLANNED_ORIGIN_LOCATION_CODE', 'PLANNED_ORIGIN_GBTT_DATETIME',\n",
    "            'PLANNED_DEST_LOCATION_CODE', 'PLANNED_DEST_GBTT_DATETIME', 'PLANNED_CALLS', 'ACTUAL_CALLS',\n",
    "            'PFPI_MINUTES', 'INCIDENT_REASON', 'INCIDENT_NUMBER', 'EVENT_TYPE', 'SECTION_CODE', 'DELAY_DAY',\n",
    "            'EVENT_DATETIME', 'INCIDENT_START_DATETIME', 'ENGLISH_DAY_TYPE', 'STATION_ROLE', 'DFT_CATEGORY',\n",
    "            'PLATFORM_COUNT', 'DATASET_TYPE', 'WEEKDAY', 'STANOX', 'DAY'\n",
    "        ]\n",
    "\n",
    "        # Display filtered columns only (in your preferred order)\n",
    "        display(incidents_on_date[cols_to_show])\n",
    "        return incidents_on_date[cols_to_show]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327544b",
   "metadata": {},
   "source": [
    "### OD pair + DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af797ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39342\\AppData\\Local\\Temp\\ipykernel_53884\\4285852890.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  all_data['INCIDENT_START_DATETIME'] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train journeys between 32530 and 11231: 17626 records found.\n",
      "Unique train service codes: ['12357820']\n",
      " 10 incident(s) found for OD pair 32530_11231 on 13-JUN-2024:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN_SERVICE_CODE</th>\n",
       "      <th>PLANNED_ORIGIN_LOCATION_CODE</th>\n",
       "      <th>PLANNED_ORIGIN_GBTT_DATETIME</th>\n",
       "      <th>PLANNED_DEST_LOCATION_CODE</th>\n",
       "      <th>PLANNED_DEST_GBTT_DATETIME</th>\n",
       "      <th>PLANNED_CALLS</th>\n",
       "      <th>ACTUAL_CALLS</th>\n",
       "      <th>PFPI_MINUTES</th>\n",
       "      <th>INCIDENT_REASON</th>\n",
       "      <th>INCIDENT_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>EVENT_DATETIME</th>\n",
       "      <th>INCIDENT_START_DATETIME</th>\n",
       "      <th>ENGLISH_DAY_TYPE</th>\n",
       "      <th>STATION_ROLE</th>\n",
       "      <th>DFT_CATEGORY</th>\n",
       "      <th>PLATFORM_COUNT</th>\n",
       "      <th>DATASET_TYPE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>STANOX</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27940</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>1029</td>\n",
       "      <td>11231</td>\n",
       "      <td>1302</td>\n",
       "      <td>1202</td>\n",
       "      <td>1205</td>\n",
       "      <td>3.0</td>\n",
       "      <td>VH</td>\n",
       "      <td>551271.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 12:05</td>\n",
       "      <td>2024-06-13 12:02:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>11720</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29857</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>1329</td>\n",
       "      <td>11231</td>\n",
       "      <td>1605</td>\n",
       "      <td>1503</td>\n",
       "      <td>1508</td>\n",
       "      <td>5.0</td>\n",
       "      <td>XA</td>\n",
       "      <td>551377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 15:08</td>\n",
       "      <td>2024-06-13 13:05:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>11720</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234961</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>0529</td>\n",
       "      <td>11231</td>\n",
       "      <td>0755</td>\n",
       "      <td>0701</td>\n",
       "      <td>0710</td>\n",
       "      <td>9.0</td>\n",
       "      <td>M8</td>\n",
       "      <td>550428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 07:10</td>\n",
       "      <td>2024-06-13 06:19:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>30120</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240227</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>1229</td>\n",
       "      <td>11231</td>\n",
       "      <td>1505</td>\n",
       "      <td>1346</td>\n",
       "      <td>1349</td>\n",
       "      <td>3.0</td>\n",
       "      <td>JL</td>\n",
       "      <td>550229.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 13:49</td>\n",
       "      <td>2024-06-13 03:18:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>30120</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497853</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>0529</td>\n",
       "      <td>11231</td>\n",
       "      <td>0755</td>\n",
       "      <td>0633</td>\n",
       "      <td>0636</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TZ</td>\n",
       "      <td>550405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 06:36</td>\n",
       "      <td>2024-06-13 06:00:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31521</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551608</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>0529</td>\n",
       "      <td>11231</td>\n",
       "      <td>0755</td>\n",
       "      <td>0633</td>\n",
       "      <td>0636</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TZ</td>\n",
       "      <td>550405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 06:36</td>\n",
       "      <td>2024-06-13 06:00:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31620</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845236</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>1829</td>\n",
       "      <td>11231</td>\n",
       "      <td>2053</td>\n",
       "      <td>1831</td>\n",
       "      <td>1837</td>\n",
       "      <td>6.0</td>\n",
       "      <td>RC</td>\n",
       "      <td>552298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 18:37</td>\n",
       "      <td>2024-06-13 18:26:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>32530</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030479</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>0529</td>\n",
       "      <td>11231</td>\n",
       "      <td>0755</td>\n",
       "      <td>0552</td>\n",
       "      <td>0619</td>\n",
       "      <td>27.0</td>\n",
       "      <td>TZ</td>\n",
       "      <td>550405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 06:19</td>\n",
       "      <td>2024-06-13 06:00:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>33087</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030898</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>0729</td>\n",
       "      <td>11231</td>\n",
       "      <td>0953</td>\n",
       "      <td>0754</td>\n",
       "      <td>0803</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TH</td>\n",
       "      <td>551532.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 08:03</td>\n",
       "      <td>2024-06-13 14:08:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>33087</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080609</th>\n",
       "      <td>12357820</td>\n",
       "      <td>32530</td>\n",
       "      <td>1229</td>\n",
       "      <td>11231</td>\n",
       "      <td>1505</td>\n",
       "      <td>1339</td>\n",
       "      <td>1341</td>\n",
       "      <td>2.0</td>\n",
       "      <td>JL</td>\n",
       "      <td>550229.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 13:41</td>\n",
       "      <td>2024-06-13 03:18:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>35136</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TRAIN_SERVICE_CODE PLANNED_ORIGIN_LOCATION_CODE  \\\n",
       "27940             12357820                        32530   \n",
       "29857             12357820                        32530   \n",
       "1234961           12357820                        32530   \n",
       "1240227           12357820                        32530   \n",
       "1497853           12357820                        32530   \n",
       "1551608           12357820                        32530   \n",
       "1845236           12357820                        32530   \n",
       "2030479           12357820                        32530   \n",
       "2030898           12357820                        32530   \n",
       "2080609           12357820                        32530   \n",
       "\n",
       "        PLANNED_ORIGIN_GBTT_DATETIME PLANNED_DEST_LOCATION_CODE  \\\n",
       "27940                           1029                      11231   \n",
       "29857                           1329                      11231   \n",
       "1234961                         0529                      11231   \n",
       "1240227                         1229                      11231   \n",
       "1497853                         0529                      11231   \n",
       "1551608                         0529                      11231   \n",
       "1845236                         1829                      11231   \n",
       "2030479                         0529                      11231   \n",
       "2030898                         0729                      11231   \n",
       "2080609                         1229                      11231   \n",
       "\n",
       "        PLANNED_DEST_GBTT_DATETIME PLANNED_CALLS ACTUAL_CALLS  PFPI_MINUTES  \\\n",
       "27940                         1302          1202         1205           3.0   \n",
       "29857                         1605          1503         1508           5.0   \n",
       "1234961                       0755          0701         0710           9.0   \n",
       "1240227                       1505          1346         1349           3.0   \n",
       "1497853                       0755          0633         0636           3.0   \n",
       "1551608                       0755          0633         0636           3.0   \n",
       "1845236                       2053          1831         1837           6.0   \n",
       "2030479                       0755          0552         0619          27.0   \n",
       "2030898                       0953          0754         0803           9.0   \n",
       "2080609                       1505          1339         1341           2.0   \n",
       "\n",
       "        INCIDENT_REASON  INCIDENT_NUMBER  ...     EVENT_DATETIME  \\\n",
       "27940                VH         551271.0  ...  13-JUN-2024 12:05   \n",
       "29857                XA         551377.0  ...  13-JUN-2024 15:08   \n",
       "1234961              M8         550428.0  ...  13-JUN-2024 07:10   \n",
       "1240227              JL         550229.0  ...  13-JUN-2024 13:49   \n",
       "1497853              TZ         550405.0  ...  13-JUN-2024 06:36   \n",
       "1551608              TZ         550405.0  ...  13-JUN-2024 06:36   \n",
       "1845236              RC         552298.0  ...  13-JUN-2024 18:37   \n",
       "2030479              TZ         550405.0  ...  13-JUN-2024 06:19   \n",
       "2030898              TH         551532.0  ...  13-JUN-2024 08:03   \n",
       "2080609              JL         550229.0  ...  13-JUN-2024 13:41   \n",
       "\n",
       "        INCIDENT_START_DATETIME ENGLISH_DAY_TYPE STATION_ROLE DFT_CATEGORY  \\\n",
       "27940       2024-06-13 12:02:00             [TH]         None          NaN   \n",
       "29857       2024-06-13 13:05:00             [TH]         None          NaN   \n",
       "1234961     2024-06-13 06:19:00             [TH]         None          NaN   \n",
       "1240227     2024-06-13 03:18:00             [TH]         None          NaN   \n",
       "1497853     2024-06-13 06:00:00             [TH]         None          NaN   \n",
       "1551608     2024-06-13 06:00:00             [TH]         None          NaN   \n",
       "1845236     2024-06-13 18:26:00             [TH]         None          NaN   \n",
       "2030479     2024-06-13 06:00:00             [TH]         None          NaN   \n",
       "2030898     2024-06-13 14:08:00             [TH]         None          NaN   \n",
       "2080609     2024-06-13 03:18:00             [TH]         None          NaN   \n",
       "\n",
       "        PLATFORM_COUNT DATASET_TYPE  WEEKDAY  STANOX DAY  \n",
       "27940              NaN   SINGLE_DAY       TH   11720  TH  \n",
       "29857              NaN   SINGLE_DAY       TH   11720  TH  \n",
       "1234961            NaN   SINGLE_DAY       TH   30120  TH  \n",
       "1240227            NaN   SINGLE_DAY       TH   30120  TH  \n",
       "1497853            NaN   SINGLE_DAY       TH   31521  TH  \n",
       "1551608            NaN   SINGLE_DAY       TH   31620  TH  \n",
       "1845236            NaN   SINGLE_DAY       TH   32530  TH  \n",
       "2030479            NaN   SINGLE_DAY       TH   33087  TH  \n",
       "2030898            NaN   SINGLE_DAY       TH   33087  TH  \n",
       "2080609            NaN   SINGLE_DAY       TH   35136  TH  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train journeys between 11231 and 32530: 11933 records found.\n",
      "Unique train service codes: ['12357820']\n",
      " 6 incident(s) found for OD pair 11231_32530 on 13-JUN-2024:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN_SERVICE_CODE</th>\n",
       "      <th>PLANNED_ORIGIN_LOCATION_CODE</th>\n",
       "      <th>PLANNED_ORIGIN_GBTT_DATETIME</th>\n",
       "      <th>PLANNED_DEST_LOCATION_CODE</th>\n",
       "      <th>PLANNED_DEST_GBTT_DATETIME</th>\n",
       "      <th>PLANNED_CALLS</th>\n",
       "      <th>ACTUAL_CALLS</th>\n",
       "      <th>PFPI_MINUTES</th>\n",
       "      <th>INCIDENT_REASON</th>\n",
       "      <th>INCIDENT_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>EVENT_DATETIME</th>\n",
       "      <th>INCIDENT_START_DATETIME</th>\n",
       "      <th>ENGLISH_DAY_TYPE</th>\n",
       "      <th>STATION_ROLE</th>\n",
       "      <th>DFT_CATEGORY</th>\n",
       "      <th>PLATFORM_COUNT</th>\n",
       "      <th>DATASET_TYPE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>STANOX</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1498005</th>\n",
       "      <td>12357820</td>\n",
       "      <td>11231</td>\n",
       "      <td>0458</td>\n",
       "      <td>32530</td>\n",
       "      <td>0715</td>\n",
       "      <td>0651</td>\n",
       "      <td>0653</td>\n",
       "      <td>1.5</td>\n",
       "      <td>TZ</td>\n",
       "      <td>550356.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 06:53</td>\n",
       "      <td>2024-06-13 05:45:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31521</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498006</th>\n",
       "      <td>12357820</td>\n",
       "      <td>11231</td>\n",
       "      <td>0458</td>\n",
       "      <td>32530</td>\n",
       "      <td>0715</td>\n",
       "      <td>0651</td>\n",
       "      <td>0653</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Q1</td>\n",
       "      <td>550356.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 06:53</td>\n",
       "      <td>2024-06-13 05:45:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31521</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500128</th>\n",
       "      <td>12357820</td>\n",
       "      <td>11231</td>\n",
       "      <td>0848</td>\n",
       "      <td>32530</td>\n",
       "      <td>1115</td>\n",
       "      <td>1057</td>\n",
       "      <td>1103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>TZ</td>\n",
       "      <td>550405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 11:03</td>\n",
       "      <td>2024-06-13 06:00:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31521</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501319</th>\n",
       "      <td>12357820</td>\n",
       "      <td>11231</td>\n",
       "      <td>1151</td>\n",
       "      <td>32530</td>\n",
       "      <td>1415</td>\n",
       "      <td>1400</td>\n",
       "      <td>1403</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>551212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 14:03</td>\n",
       "      <td>2024-06-13 12:04:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31521</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501341</th>\n",
       "      <td>12357820</td>\n",
       "      <td>11231</td>\n",
       "      <td>1151</td>\n",
       "      <td>32530</td>\n",
       "      <td>1415</td>\n",
       "      <td>1405</td>\n",
       "      <td>1408</td>\n",
       "      <td>3.0</td>\n",
       "      <td>R7</td>\n",
       "      <td>551525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 14:08</td>\n",
       "      <td>2024-06-13 14:02:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31521</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555381</th>\n",
       "      <td>12357820</td>\n",
       "      <td>11231</td>\n",
       "      <td>1151</td>\n",
       "      <td>32530</td>\n",
       "      <td>1415</td>\n",
       "      <td>1400</td>\n",
       "      <td>1403</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>551212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13-JUN-2024 14:03</td>\n",
       "      <td>2024-06-13 12:04:00</td>\n",
       "      <td>[TH]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SINGLE_DAY</td>\n",
       "      <td>TH</td>\n",
       "      <td>31620</td>\n",
       "      <td>TH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TRAIN_SERVICE_CODE PLANNED_ORIGIN_LOCATION_CODE  \\\n",
       "1498005           12357820                        11231   \n",
       "1498006           12357820                        11231   \n",
       "1500128           12357820                        11231   \n",
       "1501319           12357820                        11231   \n",
       "1501341           12357820                        11231   \n",
       "1555381           12357820                        11231   \n",
       "\n",
       "        PLANNED_ORIGIN_GBTT_DATETIME PLANNED_DEST_LOCATION_CODE  \\\n",
       "1498005                         0458                      32530   \n",
       "1498006                         0458                      32530   \n",
       "1500128                         0848                      32530   \n",
       "1501319                         1151                      32530   \n",
       "1501341                         1151                      32530   \n",
       "1555381                         1151                      32530   \n",
       "\n",
       "        PLANNED_DEST_GBTT_DATETIME PLANNED_CALLS ACTUAL_CALLS  PFPI_MINUTES  \\\n",
       "1498005                       0715          0651         0653           1.5   \n",
       "1498006                       0715          0651         0653           1.5   \n",
       "1500128                       1115          1057         1103           6.0   \n",
       "1501319                       1415          1400         1403           3.0   \n",
       "1501341                       1415          1405         1408           3.0   \n",
       "1555381                       1415          1400         1403           3.0   \n",
       "\n",
       "        INCIDENT_REASON  INCIDENT_NUMBER  ...     EVENT_DATETIME  \\\n",
       "1498005              TZ         550356.0  ...  13-JUN-2024 06:53   \n",
       "1498006              Q1         550356.0  ...  13-JUN-2024 06:53   \n",
       "1500128              TZ         550405.0  ...  13-JUN-2024 11:03   \n",
       "1501319              TA         551212.0  ...  13-JUN-2024 14:03   \n",
       "1501341              R7         551525.0  ...  13-JUN-2024 14:08   \n",
       "1555381              TA         551212.0  ...  13-JUN-2024 14:03   \n",
       "\n",
       "        INCIDENT_START_DATETIME ENGLISH_DAY_TYPE STATION_ROLE DFT_CATEGORY  \\\n",
       "1498005     2024-06-13 05:45:00             [TH]         None          NaN   \n",
       "1498006     2024-06-13 05:45:00             [TH]         None          NaN   \n",
       "1500128     2024-06-13 06:00:00             [TH]         None          NaN   \n",
       "1501319     2024-06-13 12:04:00             [TH]         None          NaN   \n",
       "1501341     2024-06-13 14:02:00             [TH]         None          NaN   \n",
       "1555381     2024-06-13 12:04:00             [TH]         None          NaN   \n",
       "\n",
       "        PLATFORM_COUNT DATASET_TYPE  WEEKDAY  STANOX DAY  \n",
       "1498005            NaN   SINGLE_DAY       TH   31521  TH  \n",
       "1498006            NaN   SINGLE_DAY       TH   31521  TH  \n",
       "1500128            NaN   SINGLE_DAY       TH   31521  TH  \n",
       "1501319            NaN   SINGLE_DAY       TH   31521  TH  \n",
       "1501341            NaN   SINGLE_DAY       TH   31521  TH  \n",
       "1555381            NaN   SINGLE_DAY       TH   31620  TH  \n",
       "\n",
       "[6 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_1 = train_view(all_data, '32530', '11231', '13-JUN-2024')\n",
    "result_2 = train_view(all_data, '11231', '32530', '13-JUN-2024')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38f5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stanox_for_service(all_data, train_service_code, origin_code, destination_code):\n",
    "    \"\"\"\n",
    "    For a given train service and OD pair, find the first train of the day (by earliest PLANNED_ORIGIN_GBTT_DATETIME),\n",
    "    then order the unique STANOX codes for that train:\n",
    "    - Use PLANNED_ORIGIN_GBTT_DATETIME for the origin,\n",
    "    - PLANNED_DEST_GBTT_DATETIME for the destination,\n",
    "    - PLANNED_CALLS for all other stations.\n",
    "    Return the ordered list of STANOX codes for that train only, always including the origin as the first element.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # --- Ensure OD_PAIR exists ---\n",
    "    if 'OD_PAIR' not in all_data.columns:\n",
    "        all_data['OD_PAIR'] = (\n",
    "            all_data['PLANNED_ORIGIN_LOCATION_CODE'].astype(str)\n",
    "            + '_' +\n",
    "            all_data['PLANNED_DEST_LOCATION_CODE'].astype(str)\n",
    "        )\n",
    "\n",
    "    od_pair = f\"{origin_code}_{destination_code}\"\n",
    "\n",
    "    # --- Filter dataset for this service and OD pair ---\n",
    "    subset = all_data[\n",
    "        (all_data['OD_PAIR'] == od_pair)\n",
    "        & (all_data['TRAIN_SERVICE_CODE'].astype(str) == str(train_service_code))\n",
    "    ].copy()\n",
    "\n",
    "    if subset.empty:\n",
    "        message = f\"üö´ No records found for train service {train_service_code} on OD pair {od_pair}.\"\n",
    "        print(message)\n",
    "        return message\n",
    "\n",
    "    # --- Find the first train of the day (earliest PLANNED_ORIGIN_GBTT_DATETIME) ---\n",
    "    subset['PLANNED_ORIGIN_GBTT_DATETIME'] = pd.to_datetime(subset['PLANNED_ORIGIN_GBTT_DATETIME'], format='%H%M', errors='coerce')\n",
    "    first_origin_time = subset['PLANNED_ORIGIN_GBTT_DATETIME'].min()\n",
    "    first_train = subset[subset['PLANNED_ORIGIN_GBTT_DATETIME'] == first_origin_time].copy()\n",
    "\n",
    "    # --- For this train, get all unique STANOX codes and their times ---\n",
    "    def get_time(row):\n",
    "        stanox = str(row['STANOX'])\n",
    "        if stanox == str(origin_code) and pd.notna(row.get('PLANNED_ORIGIN_GBTT_DATETIME', None)):\n",
    "            return pd.to_datetime(row['PLANNED_ORIGIN_GBTT_DATETIME'], format='%H%M', errors='coerce')\n",
    "        elif stanox == str(destination_code) and pd.notna(row.get('PLANNED_DEST_GBTT_DATETIME', None)):\n",
    "            return pd.to_datetime(row['PLANNED_DEST_GBTT_DATETIME'], format='%H%M', errors='coerce')\n",
    "        elif pd.notna(row.get('PLANNED_CALLS', None)) and str(row['PLANNED_CALLS']).isdigit() and len(str(row['PLANNED_CALLS'])) == 4:\n",
    "            # Use arbitrary date for time-only values to allow sorting\n",
    "            return pd.to_datetime(str(row['PLANNED_CALLS']), format='%H%M', errors='coerce')\n",
    "        else:\n",
    "            return pd.NaT\n",
    "\n",
    "    # Keep only unique STANOX for this train, keeping the earliest time for each\n",
    "    first_train['ORDER_TIME'] = first_train.apply(get_time, axis=1)\n",
    "    ordered = first_train.groupby('STANOX', as_index=False)['ORDER_TIME'].min()\n",
    "    ordered = ordered.sort_values('ORDER_TIME')\n",
    "    stanox_list = ordered['STANOX'].astype(str).tolist()\n",
    "\n",
    "    # Always include origin_code as the first element, even if not present in the data\n",
    "    origin_str = str(origin_code)\n",
    "    if origin_str in stanox_list:\n",
    "        stanox_list.remove(origin_str)\n",
    "    stanox_list = [origin_str] + stanox_list\n",
    "\n",
    "    print(f\"‚úÖ Ordered STANOX for first train of the day for service {train_service_code} on OD pair {od_pair} (origin always first):\")\n",
    "    print(stanox_list)\n",
    "    return stanox_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c34196c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ordered STANOX for first train of the day for service 12357820 on OD pair 11231_32530 (origin always first):\n",
      "['11231', '11271', '11720', '30120', '31620', '33087', '32000', '31521', '32530']\n"
     ]
    }
   ],
   "source": [
    "service_stanox = get_stanox_for_service(all_data, '12357820', '11231', '32530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdcb3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_train_journey_with_incidents(\n",
    "    all_data, service_stanox, incident_results=None,\n",
    "    stations_ref_path=r\"C:\\Users\\39342\\University of Glasgow\\Ji-Eun Byun - MZ-JB\\MSci (Research) 2024-25\\reference data\\stations_ref_with_dft.json\",\n",
    "    incident_color=\"purple\", service_code=None, date_str=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    1. Map each unique incident (INCIDENT_NUMBER, INCIDENT_START_DATETIME) as a numbered marker (chronological index), popup shows incident number, datetime and reason.\n",
    "    2. Map service_stanox as the journey sequence, connecting stations with lines.\n",
    "    3. For each STANOX, sum all PFPI_MINUTES from provided incident result DataFrames and use color-grading for the marker. Station popups list the chronological incident indices (1,2,3...) that affected them.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import folium\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load station reference\n",
    "    with open(stations_ref_path, \"r\") as f:\n",
    "        station_ref = json.load(f)\n",
    "\n",
    "    # Build station coordinates for the service_stanox sequence only\n",
    "    stanox_coords = []\n",
    "    for s in service_stanox:\n",
    "        s_str = str(int(float(s))) if isinstance(s, (int, float)) else str(s)\n",
    "        match = next((item for item in station_ref if str(item.get(\"stanox\", \"\")) == s_str), None)\n",
    "        if match and 'latitude' in match and 'longitude' in match:\n",
    "            try:\n",
    "                lat = float(match['latitude'])\n",
    "                lon = float(match['longitude'])\n",
    "                stanox_coords.append((s_str, lat, lon))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if not stanox_coords:\n",
    "        print(\"‚ö†Ô∏è No coordinates found for STANOX in this service.\")\n",
    "        return None\n",
    "\n",
    "    # --- Folium map visualization ---\n",
    "    mid_lat = sum([lat for _, lat, _ in stanox_coords]) / len(stanox_coords)\n",
    "    mid_lon = sum([lon for _, _, lon in stanox_coords]) / len(stanox_coords)\n",
    "    m = folium.Map(location=[mid_lat, mid_lon], zoom_start=8, tiles=\"CartoDB positron\")\n",
    "\n",
    "    # Add title if provided\n",
    "    if service_code and date_str:\n",
    "        title_html = f\"<div style='position: fixed; top: 10px; left: 50%; transform: translateX(-50%); z-index:9999; font-size:18px; background: white; border:2px solid grey; border-radius:8px; padding: 10px;'><b>Train Service: {service_code}</b><br><b>Date: {date_str}</b></div>\"\n",
    "        m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "    # Draw lines between each consecutive station in stanox_coords\n",
    "    for i in range(len(stanox_coords) - 1):\n",
    "        start = stanox_coords[i][1], stanox_coords[i][2]\n",
    "        end = stanox_coords[i+1][1], stanox_coords[i+1][2]\n",
    "        folium.PolyLine([start, end], color=\"blue\", weight=4, opacity=0.8).add_to(m)\n",
    "\n",
    "    # Prepare list of DataFrames from incident_results\n",
    "    dfs = []\n",
    "    if incident_results:\n",
    "        for res in incident_results:\n",
    "            if isinstance(res, pd.DataFrame):\n",
    "                dfs.append(res)\n",
    "\n",
    "    delays_df = pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "\n",
    "    # Aggregate delays for each STANOX (sum of PFPI_MINUTES for all incidents and all records)\n",
    "    stanox_delay = {}\n",
    "    stanox_incidents = {}  # maps stanox -> list of incident id strings\n",
    "    if delays_df is not None and 'STANOX' in delays_df.columns and 'PFPI_MINUTES' in delays_df.columns:\n",
    "        delays_df['PFPI_MINUTES_num'] = pd.to_numeric(delays_df['PFPI_MINUTES'], errors='coerce').fillna(0)\n",
    "        # Normalize INCIDENT_NUMBER to string for consistent display\n",
    "        if 'INCIDENT_NUMBER' in delays_df.columns:\n",
    "            def _norm_inc(x):\n",
    "                try:\n",
    "                    if pd.isna(x):\n",
    "                        return None\n",
    "                    xf = float(x)\n",
    "                    if xf.is_integer():\n",
    "                        return str(int(xf))\n",
    "                    else:\n",
    "                        return str(x)\n",
    "                except Exception:\n",
    "                    return str(x)\n",
    "            delays_df['INCIDENT_NUMBER_str'] = delays_df['INCIDENT_NUMBER'].apply(_norm_inc)\n",
    "        else:\n",
    "            delays_df['INCIDENT_NUMBER_str'] = None\n",
    "\n",
    "        for stanox, group in delays_df.groupby('STANOX'):\n",
    "            total_delay = group['PFPI_MINUTES_num'].sum()\n",
    "            stanox_delay[str(stanox)] = total_delay\n",
    "            # collect unique incident numbers for this stanox\n",
    "            if 'INCIDENT_NUMBER_str' in group.columns:\n",
    "                unique_incs = sorted([str(v) for v in pd.unique(group['INCIDENT_NUMBER_str'].dropna())])\n",
    "            else:\n",
    "                unique_incs = []\n",
    "            stanox_incidents[str(stanox)] = unique_incs\n",
    "\n",
    "    # Build chronological ranking for unique incidents (1 = earliest start time)\n",
    "    incident_rank = {}  # maps incident_id_str -> rank int\n",
    "    if delays_df is not None and 'INCIDENT_NUMBER_str' in delays_df.columns and 'INCIDENT_START_DATETIME' in delays_df.columns:\n",
    "        temp = delays_df[['INCIDENT_NUMBER_str', 'INCIDENT_START_DATETIME']].dropna(subset=['INCIDENT_NUMBER_str', 'INCIDENT_START_DATETIME']).drop_duplicates(subset=['INCIDENT_NUMBER_str']).copy()\n",
    "        if not temp.empty:\n",
    "            temp['INCIDENT_START_dt'] = pd.to_datetime(temp['INCIDENT_START_DATETIME'], errors='coerce')\n",
    "            temp = temp.sort_values('INCIDENT_START_dt')\n",
    "            temp = temp.reset_index(drop=True)\n",
    "            temp['incident_rank'] = temp.index + 1\n",
    "            incident_rank = dict(zip(temp['INCIDENT_NUMBER_str'].astype(str), temp['incident_rank'].astype(int)))\n",
    "\n",
    "    # --- Color grading function to match incident_view_heatmap_html legend ---\n",
    "    def get_color(delay):\n",
    "        try:\n",
    "            d = float(delay)\n",
    "        except Exception:\n",
    "            d = 0\n",
    "        if d == 0:\n",
    "            return \"blue\"\n",
    "        if d <= 5:\n",
    "            return '#32CD32'     # Minor (1-5 min) - Lime Green\n",
    "        elif d <= 15:\n",
    "            return '#FFD700'     # Moderate (6-15 min) - Gold\n",
    "        elif d <= 30:\n",
    "            return '#FF8C00'     # Significant (16-30 min) - Dark Orange\n",
    "        elif d <= 60:\n",
    "            return '#FF0000'     # Major (31-60 min) - Red\n",
    "        elif d <= 120:\n",
    "            return '#8B0000'     # Severe (61-120 min) - Dark Red\n",
    "        else:\n",
    "            return '#8A2BE2'     # Critical (120+ min) - Blue Violet\n",
    "\n",
    "    # Map station markers with color-grading (no delay=blue, then severity colours)\n",
    "    for stanox, lat, lon in stanox_coords:\n",
    "        delay_val = stanox_delay.get(stanox, 0)\n",
    "        color = get_color(delay_val)\n",
    "        # Prepare ranked incident list for popup, truncate if long\n",
    "        inc_list = stanox_incidents.get(stanox, [])\n",
    "        if inc_list:\n",
    "            # Map incident ids to ranks, use id fallback if rank not available\n",
    "            inc_ranks = [str(incident_rank.get(str(i), i)) for i in inc_list]\n",
    "            if len(inc_ranks) > 10:\n",
    "                inc_display = ', '.join(inc_ranks[:10]) + f', ... (+{len(inc_ranks)-10} more)'\n",
    "            else:\n",
    "                inc_display = ', '.join(inc_ranks)\n",
    "            incidents_html = f\"<br><b>Incidents (by index):</b> {inc_display}\"\n",
    "        else:\n",
    "            incidents_html = ''\n",
    "\n",
    "        popup_html = f\"<b>STANOX {stanox}</b><br>Total delay: {delay_val:.1f} min{incidents_html}\"\n",
    "        folium.CircleMarker(\n",
    "            location=(lat, lon),\n",
    "            radius=6,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_opacity=0.8,\n",
    "            popup=folium.Popup(popup_html, max_width=400)\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Map unique incidents aggregated by SECTION_CODE: create one numbered marker per location with all incident ranks\n",
    "    incident_records = pd.concat(dfs, ignore_index=True) if dfs else None\n",
    "    if incident_records is not None and 'INCIDENT_NUMBER' in incident_records.columns and 'INCIDENT_START_DATETIME' in incident_records.columns and 'SECTION_CODE' in incident_records.columns:\n",
    "        # Normalize incident id string\n",
    "        incident_records['INCIDENT_NUMBER_str'] = incident_records['INCIDENT_NUMBER'].apply(lambda x: (str(int(float(x))) if (pd.notna(x) and float(x).is_integer()) else str(x)))\n",
    "        # Build unique incident list with parsed start times\n",
    "        incident_unique = incident_records.drop_duplicates(subset=['INCIDENT_NUMBER_str', 'SECTION_CODE']).copy()\n",
    "        incident_unique['INCIDENT_START_dt'] = pd.to_datetime(incident_unique['INCIDENT_START_DATETIME'], errors='coerce')\n",
    "        # Compute incident durations\n",
    "        incident_durations = {}\n",
    "        for inc in incident_records['INCIDENT_NUMBER_str'].unique():\n",
    "            subset = incident_records[incident_records['INCIDENT_NUMBER_str'] == inc]\n",
    "            start = pd.to_datetime(subset['INCIDENT_START_DATETIME'].min(), format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "            end = pd.to_datetime(subset['EVENT_DATETIME'].max(), format='%d-%b-%Y %H:%M', errors='coerce')\n",
    "            # Ensure duration is not negative (handle data inconsistencies)\n",
    "            duration = end - start\n",
    "            duration = max(duration, pd.Timedelta(0))\n",
    "            incident_durations[inc] = duration\n",
    "        # For each SECTION_CODE, collect all incidents that occurred there\n",
    "        section_map = {}\n",
    "        for _, row in incident_unique.iterrows():\n",
    "            section = str(row['SECTION_CODE'])\n",
    "            inc_id = str(row['INCIDENT_NUMBER_str'])\n",
    "            inc_num = row.get('INCIDENT_NUMBER')\n",
    "            inc_time = row.get('INCIDENT_START_DATETIME')\n",
    "            inc_reason = row.get('INCIDENT_REASON') if 'INCIDENT_REASON' in row.index else None\n",
    "            rank = incident_rank.get(inc_id)\n",
    "            entry = {\n",
    "                'inc_id': inc_id,\n",
    "                'inc_num': inc_num,\n",
    "                'inc_time': inc_time,\n",
    "                'inc_reason': inc_reason,\n",
    "                'rank': rank if rank is not None else ''\n",
    "            }\n",
    "            section_map.setdefault(section, []).append(entry)\n",
    "\n",
    "        # For each section, sort entries by rank (if available) then plot a single numbered marker showing combined ranks\n",
    "        for section_code, entries in section_map.items():\n",
    "            # sort by rank where possible\n",
    "            entries_sorted = sorted(entries, key=lambda e: (e['rank'] if isinstance(e['rank'], int) else 999999))\n",
    "            ranks = [str(e['rank']) if e['rank'] != '' else e['inc_id'] for e in entries_sorted]\n",
    "            ranks_display = ','.join(ranks)\n",
    "            # popup lists each incident number, datetime and reason\n",
    "            popup_lines = []\n",
    "            for e in entries_sorted:\n",
    "                reason_text = e['inc_reason'] if e.get('inc_reason') else 'N/A'\n",
    "                dur = incident_durations.get(e['inc_id'], 'N/A')\n",
    "                popup_lines.append(f\"Incident: {e['inc_num']} ‚Äî {e['inc_time']} ‚Äî Reason: {reason_text} ‚Äî Duration: {dur}\")\n",
    "            popup_html = '<br>'.join(popup_lines)\n",
    "\n",
    "            # find coords for this section_code\n",
    "            match = next((item for item in station_ref if str(item.get(\"stanox\", \"\")) == section_code), None)\n",
    "            if match and 'latitude' in match and 'longitude' in match:\n",
    "                lat = float(match['latitude']) + 0.0005  # Small offset to avoid overlap with station markers\n",
    "                lon = float(match['longitude']) + 0.0005  # Small offset to avoid overlap with station markers\n",
    "                # adjust DivIcon size based on text length\n",
    "                size_px = max(28, min(80, 12 * len(ranks_display)))\n",
    "                number_html = f\"<div style='background:{incident_color};color:#fff;border-radius:50%;min-width:{size_px}px;height:{size_px}px;display:inline-flex;align-items:center;justify-content:center;font-weight:bold;border:2px solid #ffffff;padding:4px'>{ranks_display}</div>\"\n",
    "                folium.Marker(\n",
    "                    location=(lat, lon),\n",
    "                    icon=folium.DivIcon(html=number_html),\n",
    "                    popup=folium.Popup(popup_html, max_width=400)\n",
    "                ).add_to(m)\n",
    "\n",
    "    # --- Add legend/key for color grading matching incident_view_heatmap_html ---\n",
    "    legend_html = '''\n",
    "     <div style=\"position: fixed; bottom: 100px; left: 50px; width: 260px; height: 170px; z-index:9999; font-size:14px; background: white; border:2px solid grey; border-radius:8px; padding: 10px;\">\n",
    "     <b>Delay Intensity Key</b><br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:blue\"></i> 0 min (No delay)<br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:#32CD32\"></i> 1-5 min (Minor)<br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:#FFD700\"></i> 6-15 min (Moderate)<br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:#FF8C00\"></i> 16-30 min (Significant)<br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:#FF0000\"></i> 31-60 min (Major)<br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:#8B0000\"></i> 61-120 min (Severe)<br>\n",
    "     <i class=\"fa fa-circle\" style=\"color:#8A2BE2\"></i> 120+ min (Critical)<br>\n",
    "     <br><b>Incident markers:</b> numbered by chronological order (1 = earliest). Multiple ranks at same location shown as comma-separated list.<br>\n",
    "     </div>\n",
    "     '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    folium.LayerControl().add_to(m)\n",
    "    print(\"Map created for service journey and incidents with color-graded station markers and aggregated numbered incident markers.\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e385de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map created for service journey and incidents with color-graded station markers and aggregated numbered incident markers.\n"
     ]
    }
   ],
   "source": [
    "# result_1 = train_view(all_data, '32530', '11231', '13-JUN-2024')\n",
    "# result_2 = train_view(all_data, '11231', '32530', '13-JUN-2024')\n",
    "# service_stanox = get_stanox_for_service(all_data, '12357820', '11231', '32530')\n",
    "\n",
    "m = map_train_journey_with_incidents(\n",
    "    all_data,\n",
    "    service_stanox,\n",
    "    incident_results=[result_1, result_2],\n",
    "    service_code='12357820',\n",
    "    date_str='13-JUN-2024'\n",
    ")\n",
    "\n",
    "m.save(\"journey_map.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
