{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00192407",
   "metadata": {},
   "source": [
    "## This is the first attempt at testing a function for the single incident view generation as second output of the analysis\n",
    "### The function for this will be defined at the start and may be added to the utils afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f50a8",
   "metadata": {},
   "source": [
    "With INPUT: INCIDENT_CODE + DATE, the aims are\n",
    "\n",
    "-- Table with stations affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fce4a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Import with module reload to ensure latest version\n",
    "import importlib\n",
    "import outputs.utils\n",
    "importlib.reload(outputs.utils)\n",
    "from outputs.utils import incident_view, incident_view_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2e00c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station coordinates loaded: 21 stations\n",
      "Columns: ['location_id', 'name', 'description', 'tiploc', 'crs', 'nlc', 'stanox', 'notes', 'longitude', 'latitude', 'isOffNetwork', 'timingPointType', 'dft_category', 'numeric_platform_count']\n",
      "\n",
      "Sample data:\n",
      "  location_id  name            description   tiploc  crs     nlc stanox notes  \\\n",
      "0        9210  None  Birmingham New Street  BHAMNWS  BHM  112700  65630  None   \n",
      "1       15941  None          Euston London   EUSTON  EUS  144400  72410  None   \n",
      "2       16259  None      Marylebone London  MARYLBN  MYB  147500  63021  None   \n",
      "3       17082  None      St Pancras London     STPX  STP  155500  63630  None   \n",
      "4       20334  None  Liverpool Lime Street  LVRPLSH  LIV  224600  36151  None   \n",
      "\n",
      "      longitude     latitude isOffNetwork timingPointType dft_category  \\\n",
      "0  -1.898364301  52.47818683        FALSE               T            A   \n",
      "1  -0.134562782  51.52836974        FALSE               T            A   \n",
      "2  -0.163595042  51.52343241        FALSE               T            A   \n",
      "3  -0.128753901   51.5308041        FALSE               T            A   \n",
      "4   -2.97774713  53.40821014        FALSE               T            A   \n",
      "\n",
      "  numeric_platform_count  \n",
      "0                     12  \n",
      "1                     16  \n",
      "2                      6  \n",
      "3                      4  \n",
      "4                     10  \n"
     ]
    }
   ],
   "source": [
    "# Load station coordinates for mapping\n",
    "import glob\n",
    "stations_coords_file = r\"C:\\Users\\39342\\University of Glasgow\\Ji-Eun Byun - MZ-JB\\MSci (Research) 2024-25\\reference data\\category_a_stations_with_platforms.pkl\"\n",
    "\n",
    "try:\n",
    "    stations_coords = pd.read_pickle(stations_coords_file)\n",
    "    print(f\"Station coordinates loaded: {len(stations_coords)} stations\")\n",
    "    print(\"Columns:\", stations_coords.columns.tolist())\n",
    "    print(\"\\nSample data:\")\n",
    "    print(stations_coords.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Station coordinates file not found: {stations_coords_file}\")\n",
    "    stations_coords = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbc39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: c:\\Users\\39342\\University of Glasgow\\Ji-Eun Byun - MZ-JB\\RDM_analysis\n",
      "processed_data folder found!\n",
      "Found 127 pickle files\n",
      "First 5 files: ['processed_data\\\\category_a_stations_summary.pkl', 'processed_data\\\\category_a_station_12931_FR.pkl', 'processed_data\\\\category_a_station_12931_MO.pkl', 'processed_data\\\\category_a_station_12931_SA.pkl', 'processed_data\\\\category_a_station_12931_SU.pkl']\n",
      "Test file shape: (5117, 21)\n",
      "Sample incident codes: [705009.  59161. 571294. 133193. 703015.]\n"
     ]
    }
   ],
   "source": [
    "# Navigate to the RDM_analysis directory where processed_data is located\n",
    "os.chdir(r'c:\\Users\\39342\\University of Glasgow\\Ji-Eun Byun - MZ-JB\\RDM_analysis')\n",
    "current_dir = os.getcwd()\n",
    "print(f\"New working directory: {current_dir}\")\n",
    "\n",
    "# Now check for processed_data\n",
    "if os.path.exists('processed_data'):\n",
    "    print(\"processed_data folder found!\")\n",
    "    pkl_files = glob.glob('processed_data/*.pkl')\n",
    "    print(f\"Found {len(pkl_files)} pickle files\")\n",
    "    \n",
    "    if pkl_files:\n",
    "        print(\"First 5 files:\", pkl_files[:5])\n",
    "        # Filter out summary files and test loading one data file\n",
    "        data_files = [f for f in pkl_files if 'summary' not in f]\n",
    "        if data_files:\n",
    "            test_df = pd.read_pickle(data_files[0])\n",
    "            print(f\"Test file shape: {test_df.shape}\")\n",
    "            print(\"Sample incident codes:\", test_df['INCIDENT_NUMBER'].dropna().unique()[:5])\n",
    "        else:\n",
    "            print(\"No data files found (only summary files)\")\n",
    "else:\n",
    "    print(\"Still no processed_data folder found\")\n",
    "    print(\"Current directory contents:\", os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c64e1786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files (excluding summary): 126\n",
      "Test file shape: (5117, 21)\n",
      "Sample incident codes: [705009.  59161. 571294. 133193. 703015.]\n",
      "Sample incident start dates: ['09-AUG-2024 18:41' '06-DEC-2024 05:48' '21-JUN-2024 04:27']\n"
     ]
    }
   ],
   "source": [
    "# Test with the second file (skip the summary file)\n",
    "data_files = [f for f in pkl_files if 'summary' not in f]\n",
    "print(f\"Data files (excluding summary): {len(data_files)}\")\n",
    "\n",
    "if data_files:\n",
    "    test_df = pd.read_pickle(data_files[0])\n",
    "    print(f\"Test file shape: {test_df.shape}\")\n",
    "    print(\"Sample incident codes:\", test_df['INCIDENT_NUMBER'].dropna().unique()[:5])\n",
    "    print(\"Sample incident start dates:\", test_df['INCIDENT_START_DATETIME'].dropna().unique()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8a5a0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['TRAIN_SERVICE_CODE', 'PLANNED_ORIGIN_LOCATION_CODE', 'PLANNED_ORIGIN_GBTT_DATETIME', 'PLANNED_DEST_LOCATION_CODE', 'PLANNED_DEST_GBTT_DATETIME', 'PLANNED_CALLS', 'ACTUAL_CALLS', 'PFPI_MINUTES', 'INCIDENT_REASON', 'INCIDENT_NUMBER', 'EVENT_TYPE', 'SECTION_CODE', 'DELAY_DAY', 'EVENT_DATETIME', 'INCIDENT_START_DATETIME', 'ENGLISH_DAY_TYPE', 'STATION_ROLE', 'DFT_CATEGORY', 'PLATFORM_COUNT', 'DATASET_TYPE', 'WEEKDAY']\n",
      "\n",
      "Shape: (5117, 21)\n"
     ]
    }
   ],
   "source": [
    "# Get a focused view of columns and sample data\n",
    "print(\"Columns:\", test_df.columns.tolist())\n",
    "print(f\"\\nShape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING MODIFIED INCIDENT_VIEW FUNCTION ===\n",
      "\n",
      "Analyzing incident 705009:\n",
      "- Incident started: 09-AUG-2024\n",
      "- Analysis date: 09-AUG-2024 at 19:00\n",
      "- Analysis duration: 30 minutes\n",
      "Analyzing incident 705009 (started 09-AUG-2024)\n",
      "Analysis period: 09-Aug-2024 19:00 to 09-Aug-2024 19:30 (30 min)\n",
      "\n",
      "Incident originally started at: 09-AUG-2024 18:41\n",
      "Analysis period: 09-Aug-2024 19:00 to 09-Aug-2024 19:30 (30 min)\n",
      "\n",
      "Result shape: (6, 7)\n",
      "\n",
      "Detailed Results:\n",
      "  STATION_CODE  PLANNED_CALLS  ACTUAL_CALLS  DELAYED_TRAINS_OUT  \\\n",
      "0        12931              8             8                   0   \n",
      "1        16416              9             8                   1   \n",
      "2        17132             26            27                   0   \n",
      "3        54311              8            11                   2   \n",
      "4        63630              3             3                   0   \n",
      "5        87245             13            11                   2   \n",
      "\n",
      "  DELAY_MINUTES_OUT  DELAYED_TRAINS_IN                      DELAY_MINUTES_IN  \n",
      "0                []                  0                                    []  \n",
      "1             [8.0]                  0                                    []  \n",
      "2                []                  1                                [60.0]  \n",
      "3      [30.0, 90.0]                  5  [75.0, 60.0, 60.0, 30.0, 30.0, 30.0]  \n",
      "4                []                  0                                    []  \n",
      "5  [3.0, 4.0, 23.0]                  0                                    []  \n",
      "\n",
      "Incident originally started at: 09-AUG-2024 18:41\n",
      "Analysis period: 09-Aug-2024 19:00 to 09-Aug-2024 19:30 (30 min)\n",
      "\n",
      "Result shape: (6, 7)\n",
      "\n",
      "Detailed Results:\n",
      "  STATION_CODE  PLANNED_CALLS  ACTUAL_CALLS  DELAYED_TRAINS_OUT  \\\n",
      "0        12931              8             8                   0   \n",
      "1        16416              9             8                   1   \n",
      "2        17132             26            27                   0   \n",
      "3        54311              8            11                   2   \n",
      "4        63630              3             3                   0   \n",
      "5        87245             13            11                   2   \n",
      "\n",
      "  DELAY_MINUTES_OUT  DELAYED_TRAINS_IN                      DELAY_MINUTES_IN  \n",
      "0                []                  0                                    []  \n",
      "1             [8.0]                  0                                    []  \n",
      "2                []                  1                                [60.0]  \n",
      "3      [30.0, 90.0]                  5  [75.0, 60.0, 60.0, 30.0, 30.0, 30.0]  \n",
      "4                []                  0                                    []  \n",
      "5  [3.0, 4.0, 23.0]                  0                                    []  \n"
     ]
    }
   ],
   "source": [
    "# Test the modified incident_view function with new temporal parameters\n",
    "\n",
    "# Example 1: Analyze incident 705009 that started on 09-AUG-2024\n",
    "# But analyze a specific 30-minute period later in the incident lifecycle\n",
    "incident_code = 705009\n",
    "incident_date = '09-AUG-2024'    # When the incident started (for locating the incident)\n",
    "analysis_date = '09-AUG-2024'    # Date to analyze (could be same day or days later)\n",
    "analysis_hhmm = '1900'           # Start analysis at 19:00 (7:00 PM)\n",
    "period_minutes = 30              # Analyze 30 minutes from 19:00 to 19:30\n",
    "\n",
    "print(f\"\\nAnalyzing incident {incident_code}:\")\n",
    "print(f\"- Incident started: {incident_date}\")\n",
    "print(f\"- Analysis date: {analysis_date} at {analysis_hhmm[:2]}:{analysis_hhmm[2:]}\")\n",
    "print(f\"- Analysis duration: {period_minutes} minutes\")\n",
    "\n",
    "result, incident_start, analysis_period = incident_view(incident_code, incident_date, analysis_date, analysis_hhmm, period_minutes)\n",
    "\n",
    "print(f\"\\nIncident originally started at: {incident_start}\")\n",
    "print(f\"Analysis period: {analysis_period}\")\n",
    "print(f\"\\nResult shape: {result.shape}\")\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "15aad811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE 3: Multi-day incident analysis\n",
      "\n",
      "Analyzing incident 705009 on the day after it started:\n",
      "- Incident started: 09-AUG-2024\n",
      "- Analysis date: 10-Aug-2024 at 08:00\n",
      "- Analysis duration: 60 minutes\n",
      "Analyzing incident 705009 (started 09-AUG-2024)\n",
      "Analysis period: 10-Aug-2024 08:00 to 10-Aug-2024 09:00 (60 min)\n",
      "\n",
      "Incident originally started at: 09-AUG-2024 18:41\n",
      "Analysis period: 10-Aug-2024 08:00 to 10-Aug-2024 09:00 (60 min)\n",
      "\n",
      "Result shape: (4, 7)\n",
      "\n",
      "Detailed Results:\n",
      "  STATION_CODE  PLANNED_CALLS  ACTUAL_CALLS  DELAYED_TRAINS_OUT  \\\n",
      "0        12931             18            17                   1   \n",
      "1        16416             17            16                   1   \n",
      "2        17132             37            36                   1   \n",
      "3        54311             11             9                   4   \n",
      "\n",
      "          DELAY_MINUTES_OUT  DELAYED_TRAINS_IN    DELAY_MINUTES_IN  \n",
      "0              [80.0, 80.0]                  0                  []  \n",
      "1                    [75.0]                  0                  []  \n",
      "2              [17.0, 60.0]                  0                  []  \n",
      "3  [60.0, 30.0, 30.0, 75.0]                  2  [60.0, 60.0, 30.0]  \n",
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL THREE ANALYSES:\n",
      "Same day 19:00-19:30: 6 stations\n",
      "Same day 20:15-21:00: 6 stations\n",
      "Next day 08:00-09:00: 4 stations\n",
      "\n",
      "Incident originally started at: 09-AUG-2024 18:41\n",
      "Analysis period: 10-Aug-2024 08:00 to 10-Aug-2024 09:00 (60 min)\n",
      "\n",
      "Result shape: (4, 7)\n",
      "\n",
      "Detailed Results:\n",
      "  STATION_CODE  PLANNED_CALLS  ACTUAL_CALLS  DELAYED_TRAINS_OUT  \\\n",
      "0        12931             18            17                   1   \n",
      "1        16416             17            16                   1   \n",
      "2        17132             37            36                   1   \n",
      "3        54311             11             9                   4   \n",
      "\n",
      "          DELAY_MINUTES_OUT  DELAYED_TRAINS_IN    DELAY_MINUTES_IN  \n",
      "0              [80.0, 80.0]                  0                  []  \n",
      "1                    [75.0]                  0                  []  \n",
      "2              [17.0, 60.0]                  0                  []  \n",
      "3  [60.0, 30.0, 30.0, 75.0]                  2  [60.0, 60.0, 30.0]  \n",
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL THREE ANALYSES:\n",
      "Same day 19:00-19:30: 6 stations\n",
      "Same day 20:15-21:00: 6 stations\n",
      "Next day 08:00-09:00: 4 stations\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Demonstrate analyzing incident on a different date (for multi-day incidents)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE 3: Multi-day incident analysis\")\n",
    "\n",
    "# For demonstration, let's try analyzing the incident on the next day\n",
    "# (This would work if the incident lasted multiple days)\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "incident_start_dt = datetime.strptime(incident_date, '%d-%b-%Y')\n",
    "next_day = incident_start_dt + timedelta(days=1)\n",
    "analysis_date_next = next_day.strftime('%d-%b-%Y')\n",
    "\n",
    "analysis_hhmm_3 = '0800'           # Start analysis at 08:00 next day\n",
    "period_minutes_3 = 60              # Analyze 60 minutes\n",
    "\n",
    "print(f\"\\nAnalyzing incident {incident_code} on the day after it started:\")\n",
    "print(f\"- Incident started: {incident_date}\")\n",
    "print(f\"- Analysis date: {analysis_date_next} at {analysis_hhmm_3[:2]}:{analysis_hhmm_3[2:]}\")\n",
    "print(f\"- Analysis duration: {period_minutes_3} minutes\")\n",
    "\n",
    "result3, incident_start3, analysis_period3 = incident_view(incident_code, incident_date, analysis_date_next, analysis_hhmm_3, period_minutes_3)\n",
    "\n",
    "print(f\"\\nIncident originally started at: {incident_start3}\")\n",
    "print(f\"Analysis period: {analysis_period3}\")\n",
    "print(f\"\\nResult shape: {result3.shape}\")\n",
    "\n",
    "if not result3.empty:\n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(result3)\n",
    "else:\n",
    "    print(\"No data found for this analysis period (incident may not have lasted this long)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF ALL THREE ANALYSES:\")\n",
    "print(f\"Same day 19:00-19:30: {len(result)} stations\")\n",
    "print(f\"Same day 20:15-21:00: {len(result2)} stations\") \n",
    "print(f\"Next day 08:00-09:00: {len(result3)} stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b8f51",
   "metadata": {},
   "source": [
    "### Concrete Example:\n",
    "\n",
    "Incident starts: 09:00\n",
    "\n",
    "Period: 60 minutes (09:00-10:00)\n",
    "\n",
    "Train A: Originally scheduled 09:30, delayed 80 minutes ‚Üí arrives 10:50\n",
    "\n",
    "This train is counted in DELAYED_TRAINS_OUT (was supposed to be in 09:00-10:00 window)\n",
    "\n",
    "Train B: Originally scheduled 08:30, delayed 45 minutes ‚Üí arrives 09:15\n",
    "\n",
    "This train is counted in DELAYED_TRAINS_IN (shifted into 09:00-10:00 window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b17c9a",
   "metadata": {},
   "source": [
    "## Testing html function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Output file: 'incident_705009_09_AUG_2024_1900_period60min_interval10min.html'\n",
      "Creating dynamic HTML map for incident 705009\n",
      "Analysis period: 09-Aug-2024 19:00 to 09-Aug-2024 20:00\n",
      "Interval size: 10 minutes\n",
      "Total intervals: 6\n",
      "Found delay data for 4 stations\n",
      " DYNAMIC DELAY MAP CREATED! \n",
      "File: incident_705009_09_AUG_2024_1900_period60min_interval10min.html\n",
      "Time steps: 6 (10-minute intervals)\n",
      "Stations mapped: 4\n",
      " Features: Play/Pause controls, Color-coded delays, Interval-specific timeline\n",
      " Open the HTML file in your browser to explore the dynamic timeline!\n",
      "Found delay data for 4 stations\n",
      " DYNAMIC DELAY MAP CREATED! \n",
      "File: incident_705009_09_AUG_2024_1900_period60min_interval10min.html\n",
      "Time steps: 6 (10-minute intervals)\n",
      "Stations mapped: 4\n",
      " Features: Play/Pause controls, Color-coded delays, Interval-specific timeline\n",
      " Open the HTML file in your browser to explore the dynamic timeline!\n"
     ]
    }
   ],
   "source": [
    "# Test the CORRECTED temporal logic with configurable intervals\n",
    "\n",
    "# Test parameters - MODIFY THESE AS NEEDED\n",
    "incident_code = 705009\n",
    "incident_date = '09-AUG-2024'\n",
    "analysis_date = '09-AUG-2024'\n",
    "analysis_hhmm = '1900'\n",
    "period_minutes = 60              # Total analysis period: 60 minutes (19:00-20:00)\n",
    "interval_minutes = 10            # Split into 10-minute intervals\n",
    "\n",
    "\n",
    "# Create DYNAMIC variable name and file name based on parameters\n",
    "safe_date = analysis_date.replace('-', '_')\n",
    "variable_name = f\"html_inc{incident_code}_{safe_date}_{analysis_hhmm}_p{period_minutes}m_i{interval_minutes}m\"\n",
    "file_name = f'incident_{incident_code}_{safe_date}_{analysis_hhmm}_period{period_minutes}min_interval{interval_minutes}min.html'\n",
    "\n",
    "print(f\"üìù Creating variable: '{variable_name}'\")\n",
    "print(f\"üìÅ Output file: '{file_name}'\")\n",
    "\n",
    "# Create HTML with dynamic naming (with proper syntax highlighting)\n",
    "html_result = incident_view_html(\n",
    "    incident_code, incident_date, analysis_date, analysis_hhmm, \n",
    "    period_minutes, interval_minutes, \n",
    "    file_name\n",
    ")\n",
    "\n",
    "# Store the result in a dynamic variable name using globals()\n",
    "globals()[variable_name] = html_result\n",
    "\n",
    "print(f\"‚úÖ HTML map created and stored in variable: {variable_name}\")\n",
    "print(f\"üí° Access your result with: {variable_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Output file: 'incident_705009_10_AUG_2024_0800_period360min_interval30min.html'\n",
      "Creating dynamic HTML map for incident 705009\n",
      "Analysis period: 10-Aug-2024 08:00 to 10-Aug-2024 14:00\n",
      "Interval size: 30 minutes\n",
      "Total intervals: 12\n",
      "Found delay data for 4 stations\n",
      " DYNAMIC DELAY MAP CREATED! \n",
      "File: incident_705009_10_AUG_2024_0800_period360min_interval30min.html\n",
      "Time steps: 12 (30-minute intervals)\n",
      "Stations mapped: 4\n",
      " Features: Play/Pause controls, Color-coded delays, Interval-specific timeline\n",
      " Open the HTML file in your browser to explore the dynamic timeline!\n",
      "Found delay data for 4 stations\n",
      " DYNAMIC DELAY MAP CREATED! \n",
      "File: incident_705009_10_AUG_2024_0800_period360min_interval30min.html\n",
      "Time steps: 12 (30-minute intervals)\n",
      "Stations mapped: 4\n",
      " Features: Play/Pause controls, Color-coded delays, Interval-specific timeline\n",
      " Open the HTML file in your browser to explore the dynamic timeline!\n"
     ]
    }
   ],
   "source": [
    "# ANOTHER TEST with different parameters, NEXT DAY\n",
    "\n",
    "# Test parameters - MODIFY THESE AS NEEDED\n",
    "incident_code = 705009           # unique identifier\n",
    "incident_date = '09-AUG-2024'    # unique identifier\n",
    "analysis_date = '10-AUG-2024'\n",
    "analysis_hhmm = '0800'\n",
    "period_minutes = 360              # Total analysis period: 360 minutes\n",
    "interval_minutes = 30            # Split into 30-minute intervals\n",
    "\n",
    "\n",
    "# Create DYNAMIC variable name and file name based on parameters\n",
    "safe_date = analysis_date.replace('-', '_')\n",
    "variable_name = f\"html_inc{incident_code}_{safe_date}_{analysis_hhmm}_p{period_minutes}m_i{interval_minutes}m\"\n",
    "file_name = f'incident_{incident_code}_{safe_date}_{analysis_hhmm}_period{period_minutes}min_interval{interval_minutes}min.html'\n",
    "\n",
    "print(f\"üìù Creating variable: '{variable_name}'\")\n",
    "print(f\"üìÅ Output file: '{file_name}'\")\n",
    "\n",
    "# Create HTML with dynamic naming (with proper syntax highlighting)\n",
    "html_result = incident_view_html(\n",
    "    incident_code, incident_date, analysis_date, analysis_hhmm, \n",
    "    period_minutes, interval_minutes, \n",
    "    file_name\n",
    ")\n",
    "\n",
    "# Store the result in a dynamic variable name using globals()\n",
    "globals()[variable_name] = html_result\n",
    "\n",
    "print(f\"‚úÖ HTML map created and stored in variable: {variable_name}\")\n",
    "print(f\"üí° Access your result with: {variable_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
